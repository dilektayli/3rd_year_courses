{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T18:04:38.954104Z","iopub.execute_input":"2023-05-13T18:04:38.955304Z","iopub.status.idle":"2023-05-13T18:04:38.996611Z","shell.execute_reply.started":"2023-05-13T18:04:38.955236Z","shell.execute_reply":"2023-05-13T18:04:38.995313Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-competition-for-kaggle-learn-users/train.csv\n/kaggle/input/housing-prices-competition-for-kaggle-learn-users/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/train.csv', index_col='Id')\nX_test_full = pd.read_csv('../input/housing-prices-competition-for-kaggle-learn-users/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll use only numerical predictors\nX = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:04:41.982594Z","iopub.execute_input":"2023-05-13T18:04:41.983025Z","iopub.status.idle":"2023-05-13T18:04:42.902336Z","shell.execute_reply.started":"2023-05-13T18:04:41.982993Z","shell.execute_reply":"2023-05-13T18:04:42.901087Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:04:48.737177Z","iopub.execute_input":"2023-05-13T18:04:48.737565Z","iopub.status.idle":"2023-05-13T18:04:49.101475Z","shell.execute_reply.started":"2023-05-13T18:04:48.737536Z","shell.execute_reply":"2023-05-13T18:04:49.100489Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Q1\n\ncols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n\nprint(\"MAE from Approach 1 (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:04:51.603332Z","iopub.execute_input":"2023-05-13T18:04:51.603755Z","iopub.status.idle":"2023-05-13T18:04:52.951743Z","shell.execute_reply.started":"2023-05-13T18:04:51.603724Z","shell.execute_reply":"2023-05-13T18:04:52.950268Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"MAE from Approach 1 (Drop columns with missing values):\n17837.82570776256\n","output_type":"stream"}]},{"cell_type":"code","source":"#Q2\n\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer(strategy=\"median\")\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n\n# Imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\nprint(\"MAE from Approach 2 (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:05:23.211048Z","iopub.execute_input":"2023-05-13T18:05:23.212581Z","iopub.status.idle":"2023-05-13T18:05:24.661817Z","shell.execute_reply.started":"2023-05-13T18:05:23.212517Z","shell.execute_reply":"2023-05-13T18:05:24.660638Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Imputation):\n17791.59899543379\n","output_type":"stream"}]},{"cell_type":"code","source":"#Q3\n\n#copy before imputation\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n#add new columns for imputing\nfor col in cols_with_missing:\n    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n\nmy_imputer = SimpleImputer(strategy='median') \n\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n\n# Imputation removed column names; put them back\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:05:29.815457Z","iopub.execute_input":"2023-05-13T18:05:29.815869Z","iopub.status.idle":"2023-05-13T18:05:31.341407Z","shell.execute_reply.started":"2023-05-13T18:05:29.815840Z","shell.execute_reply":"2023-05-13T18:05:31.340456Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (An Extension to Imputation):\n18063.910194063923\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#Q4\n\ncols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n\n# Drop columns\nreduced_X = X.drop(cols_with_missing, axis=1)\nreduced_X_test = X_test.drop(cols_with_missing, axis=1)\n\n\n# Apply SimpleImputer on reduced_X and reduced_X_test\nmy_imputer = SimpleImputer(strategy='median')\n\nreduced_imputed_X = pd.DataFrame(my_imputer.fit_transform(reduced_X))\nreduced_imputed_X_test = pd.DataFrame(my_imputer.transform(reduced_X_test))\n\n# Imputation removed column names; put them back\nreduced_imputed_X.columns = reduced_X.columns\nreduced_imputed_X_test.columns = reduced_X_test.columns\n\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(reduced_imputed_X, y)\n\npredictions = model.predict(reduced_imputed_X_test)\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission_drop_columns.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:06:07.210531Z","iopub.execute_input":"2023-05-13T18:06:07.210957Z","iopub.status.idle":"2023-05-13T18:06:08.884083Z","shell.execute_reply.started":"2023-05-13T18:06:07.210921Z","shell.execute_reply":"2023-05-13T18:06:08.883133Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Leaderboard score: 16381.48041","metadata":{}},{"cell_type":"code","source":"#Q5\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer(strategy='median')\n\nimputed_X = pd.DataFrame(my_imputer.fit_transform(X))\nimputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n\n# Imputation removed column names; put them back\nimputed_X.columns = X.columns\nimputed_X_test.columns = X_test.columns\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X, y)\n\npredictions = model.predict(imputed_X_test)\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission_impute_median.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:07:05.461269Z","iopub.execute_input":"2023-05-13T18:07:05.462248Z","iopub.status.idle":"2023-05-13T18:07:07.292646Z","shell.execute_reply.started":"2023-05-13T18:07:05.462195Z","shell.execute_reply":"2023-05-13T18:07:07.291605Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Leaderboard score: 16452.43726","metadata":{}},{"cell_type":"code","source":"#Q6 \n\nX_plus = X.copy()\nX_test_plus = X_test.copy()\n\n#add new columns indicating for imputing\nfor col in cols_with_missing:\n    X_plus[col + '_was_missing'] = X[col].isnull()\n    X_test_plus[col + '_was_missing'] = X_test[col].isnull()\n\nmy_imputer = SimpleImputer(strategy='median') \n\nimputed_X_plus = pd.DataFrame(my_imputer.fit_transform(X_plus))\nimputed_X_test_plus = pd.DataFrame(my_imputer.transform(X_test_plus))\n\n# Imputation removed column names; put them back\nimputed_X_plus.columns = X_plus.columns\nimputed_X_test_plus.columns = X_test_plus.columns\n\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X_plus, y)\n\npredictions = model.predict(imputed_X_test_plus)\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission_impute_plus_median.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T18:08:17.423477Z","iopub.execute_input":"2023-05-13T18:08:17.424708Z","iopub.status.idle":"2023-05-13T18:08:19.355002Z","shell.execute_reply.started":"2023-05-13T18:08:17.424651Z","shell.execute_reply":"2023-05-13T18:08:19.353996Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Leaderboard Score: 16451.15081","metadata":{}}]}